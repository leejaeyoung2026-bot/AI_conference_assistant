<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VORA 기술 블로그 - STT & AI 최신 소식</title>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6874320463657568"
     crossorigin="anonymous"></script>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700;900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
    <style>
        :root {
            --primary: #6366f1;
            --primary-hover: #4f46e5;
            --bg-main: #0f172a;
            --bg-panel: #1e293b;
            --text-main: #f1f5f9;
            --text-muted: #94a3b8;
            --accent: #06b6d4;
            --card-shadow: 0 10px 25px -5px rgba(0, 0, 0, 0.3), 0 8px 10px -6px rgba(0, 0, 0, 0.3);
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Noto Sans KR', sans-serif;
            background: var(--bg-main);
            color: var(--text-main);
            line-height: 1.6;
        }

        header {
            background: rgba(15, 23, 42, 0.9);
            backdrop-filter: blur(10px);
            padding: 20px 40px;
            position: sticky;
            top: 0;
            z-index: 1000;
            border-bottom: 1px solid rgba(255,255,255,0.05);
        }

        nav {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .logo { font-size: 1.5rem; font-weight: 900; color: white; text-decoration: none; letter-spacing: -1px; }
        .nav-links { display: flex; gap: 30px; align-items: center; }
        .nav-links a { color: var(--text-muted); text-decoration: none; font-size: 0.95rem; transition: 0.3s; }
        .nav-links a:hover { color: var(--primary); }
        .lang-switch { font-weight: 700; color: var(--primary) !important; }

        /* Blog Hero */
        .blog-hero {
            padding: 100px 20px 60px;
            text-align: center;
            background: radial-gradient(circle at center, rgba(99, 102, 241, 0.15) 0%, transparent 70%);
        }
        .blog-hero h1 { font-size: 3.5rem; font-weight: 900; margin-bottom: 20px; letter-spacing: -2px; }
        .blog-hero p { color: var(--text-muted); font-size: 1.2rem; max-width: 600px; margin: 0 auto; }

        /* Board Container */
        .container {
            max-width: 1200px;
            margin: 0 auto 100px;
            padding: 0 20px;
            display: grid;
            grid-template-columns: 1fr 300px;
            gap: 40px;
        }

        /* Post Grid */
        .blog-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(100%, 1fr));
            gap: 30px;
        }

        .blog-card {
            background: var(--bg-panel);
            border-radius: 20px;
            overflow: hidden;
            border: 1px solid rgba(255,255,255,0.05);
            transition: 0.3s;
            display: flex;
            flex-direction: row;
            height: 280px;
            cursor: pointer;
        }
        .blog-card:hover {
            transform: translateY(-5px);
            border-color: var(--primary);
            box-shadow: var(--card-shadow);
        }

        .card-image {
            width: 35%;
            background-size: cover;
            background-position: center;
            position: relative;
        }

        .card-content {
            width: 65%;
            padding: 30px;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }

        .card-tag {
            display: inline-block;
            padding: 4px 12px;
            background: rgba(99, 102, 241, 0.1);
            color: var(--primary);
            border-radius: 999px;
            font-size: 0.75rem;
            font-weight: 700;
            margin-bottom: 15px;
            text-transform: uppercase;
        }

        .blog-card h2 {
            font-size: 1.6rem;
            margin-bottom: 15px;
            line-height: 1.3;
            color: #fff;
        }

        .blog-card p {
            color: var(--text-muted);
            font-size: 0.95rem;
            margin-bottom: 20px;
            display: -webkit-box;
            -webkit-line-clamp: 3;
            -webkit-box-orient: vertical;
            overflow: hidden;
        }

        .card-footer {
            margin-top: auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 0.85rem;
            color: var(--text-muted);
        }

        /* Modal Style */
        .modal {
            display: none;
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            background: rgba(7, 11, 26, 0.95);
            z-index: 2000;
            overflow-y: auto;
            padding: 40px 20px;
        }
        .modal.active { display: block; }
        .modal-content {
            max-width: 850px;
            margin: 0 auto;
            background: var(--bg-panel);
            border-radius: 30px;
            padding: 60px;
            position: relative;
            border: 1px solid rgba(255,255,255,0.1);
            box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.5);
        }
        .modal-close {
            position: absolute;
            top: 30px; right: 30px;
            font-size: 2rem;
            color: var(--text-muted);
            cursor: pointer;
            transition: 0.3s;
        }
        .modal-close:hover { color: #fff; }
        
        .post-header { margin-bottom: 40px; border-bottom: 1px solid rgba(255,255,255,0.05); padding-bottom: 30px; }
        .post-header h2 { font-size: 2.5rem; color: #fff; margin: 15px 0; line-height: 1.2; }
        .post-meta { display: flex; gap: 20px; color: var(--text-muted); font-size: 0.9rem; }

        .post-body { font-size: 1.15rem; line-height: 1.8; color: #cbd5e1; }
        .post-body h3 { color: #fff; margin: 40px 0 20px; font-size: 1.5rem; border-left: 4px solid var(--primary); padding-left: 15px; }
        .post-body p { margin-bottom: 25px; text-align: justify; }
        .post-body ul { margin-bottom: 30px; padding-left: 25px; }
        .post-body li { margin-bottom: 12px; }
        .post-body strong { color: var(--primary); }

        @media (max-width: 992px) {
            .container { grid-template-columns: 1fr; }
            .blog-card { flex-direction: column; height: auto; }
            .card-image { width: 100%; height: 200px; }
            .card-content { width: 100%; }
            .modal-content { padding: 30px; border-radius: 20px; }
            .post-header h2 { font-size: 1.8rem; }
        }

        footer { padding: 80px 20px; border-top: 1px solid rgba(255,255,255,0.05); text-align: center; color: var(--text-muted); }
    </style>
</head>
<body>
    <header>
        <nav>
            <a href="index.html" class="logo">VORA</a>
            <div class="nav-links">
                <a href="index.html">홈</a>
                <a href="blog.html" style="color: var(--primary);">기술 블로그</a>
                <a href="faq.html">FAQ</a>
                <a href="blog_en.html" class="lang-switch"><i class="fas fa-globe"></i> EN</a>
                <a href="app.html" style="background: var(--primary); color: white !important; padding: 8px 20px; border-radius: 8px; font-weight: 700;">지금 시작하기</a>
            </div>
        </nav>
    </header>

    <section class="blog-hero">
        <div class="card-tag">TECH INSIGHTS</div>
        <h1>STT & AI Knowledge Base</h1>
        <p>최신 음성 인식 모델과 대규모 언어 모델(LLM)의 실제 성능을 심층 분석합니다.</p>
    </section>

    <div class="container">
        <main class="blog-grid" id="blogGrid">
            <!-- Post 1: OpenAI Whisper v3 -->
            <article class="blog-card" onclick="openPost(1)">
                <div class="card-image" style="background-image: url('https://images.unsplash.com/photo-1677442136019-21780ecad995?auto=format&fit=crop&q=80&w=800');"></div>
                <div class="card-content">
                    <span class="card-tag">STT MODEL</span>
                    <h2>OpenAI Whisper v3: 128 Mel Bins로 진화한 인식 성능</h2>
                    <p>OpenAI의 최신 Whisper v3 모델은 기존 80 Mel bins에서 128로 아키텍처를 확장하여 한국어 포함 다국어 인식률을 획기적으로 개선했습니다. 실제 WER 성능 변화를 살펴봅니다.</p>
                    <div class="card-footer">
                        <span><i class="far fa-calendar-alt"></i> 2026. 02. 05</span>
                        <span><i class="far fa-user"></i> VORA Research</span>
                    </div>
                </div>
            </article>

            <!-- Post 2: Gemini 2.0 Flash -->
            <article class="blog-card" onclick="openPost(2)">
                <div class="card-image" style="background-image: url('https://images.unsplash.com/photo-1620712943543-bcc4688e7485?auto=format&fit=crop&q=80&w=800');"></div>
                <div class="card-content">
                    <span class="card-tag">AI ANALYSIS</span>
                    <h2>Gemini 2.0 Flash GA: 실시간 멀티모달 시대의 개막</h2>
                    <p>2025년 2월 정식 출시된 Gemini 2.0 Flash는 1.5 Flash 대비 2배 빠른 처리 속도와 강력한 실시간 추론 능력을 갖추었습니다. VORA의 엔진에 미치는 영향을 분석합니다.</p>
                    <div class="card-footer">
                        <span><i class="far fa-calendar-alt"></i> 2026. 02. 06</span>
                        <span><i class="far fa-user"></i> AI Engineer</span>
                    </div>
                </div>
            </article>

            <!-- Post 3: Open Source STT Trends -->
            <article class="blog-card" onclick="openPost(3)">
                <div class="card-image" style="background-image: url('https://images.unsplash.com/photo-1550751827-4bd374c3f58b?auto=format&fit=crop&q=80&w=800');"></div>
                <div class="card-content">
                    <span class="card-tag">OPEN SOURCE</span>
                    <h2>2026 오픈소스 STT 트렌드: On-Device & Low Latency</h2>
                    <p>Moonshine, Canary Qwen, Sherpa-ONNX 등 2026년 주목받는 오픈소스 STT 모델들을 비교합니다. 클라우드 의존도를 낮추고 보안을 강화하는 최신 아키텍처를 탐구합니다.</p>
                    <div class="card-footer">
                        <span><i class="far fa-calendar-alt"></i> 2026. 01. 30</span>
                        <span><i class="far fa-user"></i> VORA Dev Team</span>
                    </div>
                </div>
            </article>
        </main>

        <aside class="sidebar">
            <div class="widget">
                <h3>카테고리</h3>
                <ul class="category-list">
                    <li><span>STT 기술 분석</span></li>
                    <li><span>LLM & 추론</span></li>
                    <li><span>온디바이스 AI</span></li>
                    <li><span>데이터 보안</span></li>
                </ul>
            </div>
        </aside>
    </div>

    <!-- Modal Container -->
    <div class="modal" id="postModal">
        <div class="modal-content">
            <span class="modal-close" onclick="closePost()">&times;</span>
            <div id="modalBody">
                <!-- Content will be injected here -->
            </div>
        </div>
    </div>

    <footer>
        <p>© 2026 VORA. Empowering professional communication with intelligent AI solutions.</p>
    </footer>

    <script>
        const posts = {
            1: {
                tag: "STT MODEL",
                title: "OpenAI Whisper v3: 128 Mel Bins로 진화한 인식 성능",
                author: "VORA Research",
                date: "2026. 02. 05",
                content: `
                    <div class="post-header">
                        <span class="card-tag">STT MODEL</span>
                        <h2>OpenAI Whisper v3: 128 Mel Bins로 진화한 인식 성능</h2>
                        <div class="post-meta">
                            <span><i class="far fa-user"></i> VORA Research</span>
                            <span><i class="far fa-calendar-alt"></i> 2026. 02. 05</span>
                        </div>
                    </div>
                    <div class="post-body">
                        <p>OpenAI는 2023년 말 Whisper v3를 출시하며 음성 인식 분야의 새로운 표준을 제시했습니다. 이전 버전인 v2와 비교했을 때 가장 큰 변화는 아키텍처의 확장과 다국어 데이터의 정교화입니다.</p>
                        
                        <h3>주요 기술적 개선 사항</h3>
                        <ul>
                            <li><strong>Mel Frequency Bins 확장:</strong> 기존 80 bins에서 128 bins로 확장되었습니다. 이는 오디오 신호에서 더 세밀한 특징을 추출할 수 있게 하여, 배경 소음이 심하거나 목소리가 작은 환경에서도 인식 정확도를 높여줍니다.</li>
                            <li><strong>에러율(WER) 감소:</strong> Whisper v2 대비 비영어권 언어에서 20~30%의 오류 감소율을 보여줍니다. 특히 한국어의 경우, 대화체와 전문 용어 인식 성능이 눈에 띄게 향상되었습니다.</li>
                            <li><strong>V3 Turbo의 등장:</strong> 처리 속도를 획기적으로 높인 Turbo 모델은 실시간성이 중요한 VORA와 같은 서비스에서 핵심적인 역할을 수행합니다.</li>
                        </ul>

                        <h3>VORA의 도입 전략</h3>
                        <p>VORA는 Whisper v3 아키텍처를 기반으로 사용자 브라우저에서 직접 구동되는 온디바이스 STT와 클라우드 정밀 STT를 혼합하여 사용합니다. 이를 통해 보안성과 정확도라는 두 마리 토끼를 잡고 있습니다.</p>
                    </div>
                `
            },
            2: {
                tag: "AI ANALYSIS",
                title: "Gemini 2.0 Flash GA: 실시간 멀티모달 시대의 개막",
                author: "AI Engineer",
                date: "2026. 02. 06",
                content: `
                    <div class="post-header">
                        <span class="card-tag">AI ANALYSIS</span>
                        <h2>Gemini 2.0 Flash GA: 실시간 멀티모달 시대의 개막</h2>
                        <div class="post-meta">
                            <span><i class="far fa-user"></i> AI Engineer</span>
                            <span><i class="far fa-calendar-alt"></i> 2026. 02. 06</span>
                        </div>
                    </div>
                    <div class="post-body">
                        <p>Google은 2025년 2월 5일, Gemini 2.0 Flash의 일반 가용성(GA)을 발표했습니다. 이 모델은 "Flash"라는 이름에 걸맞게 극도로 빠른 응답 속도와 효율성에 초점이 맞춰져 있습니다.</p>
                        
                        <h3>왜 2.0 Flash인가?</h3>
                        <ul>
                            <li><strong>압도적인 속도:</strong> Gemini 1.5 Flash 대비 첫 토큰 출력 속도(TTFT)가 2배 이상 빨라졌습니다. 이는 VORA의 '실시간 질문 답변' 기능에서 지연 시간을 거의 느낄 수 없게 만듭니다.</li>
                            <li><strong>100만 토큰 컨텍스트:</strong> 거대한 컨텍스트 윈도우를 유지하면서도 속도를 놓치지 않았습니다. 10시간이 넘는 마라톤 회의 데이터도 한 번에 처리하여 요약할 수 있습니다.</li>
                            <li><strong>기본 도구 사용(Native Tool Use):</strong> 구글 검색 검색 기능을 기본적으로 지원하여, 회의 중 모르는 용어가 나오면 AI가 실시간으로 최신 정보를 검색하여 답변의 정확도를 높여줍니다.</li>
                        </ul>

                        <h3>VORA 엔진과의 시너지</h3>
                        <p>현재 VORA는 Gemini 2.0 Flash API를 통해 실시간 보정 및 요약을 수행합니다. 특히 멀티모달 능력을 활용하여 향후 회의 중 공유되는 이미지나 차트까지 분석하는 기능을 준비 중입니다.</p>
                    </div>
                `
            },
            3: {
                tag: "OPEN SOURCE",
                title: "2026 오픈소스 STT 트렌드: On-Device & Low Latency",
                author: "VORA Dev Team",
                date: "2026. 01. 30",
                content: `
                    <div class="post-header">
                        <span class="card-tag">OPEN SOURCE</span>
                        <h2>2026 오픈소스 STT 트렌드: On-Device & Low Latency</h2>
                        <div class="post-meta">
                            <span><i class="far fa-user"></i> VORA Dev Team</span>
                            <span><i class="far fa-calendar-alt"></i> 2026. 01. 30</span>
                        </div>
                    </div>
                    <div class="post-body">
                        <p>2026년 STT 시장은 대형 클라우드 모델뿐만 아니라, 로컬 장치에서 돌아가는 가벼우면서도 강력한 오픈소스 모델들이 주도하고 있습니다.</p>
                        
                        <h3>주목해야 할 오픈소스 모델</h3>
                        <ul>
                            <li><strong>Canary Qwen 2.5B:</strong> 영어권에서 극강의 정확도를 보여주며, 적은 파라미터로도 엔터프라이즈급 성능을 발휘합니다.</li>
                            <li><strong>Sherpa-ONNX:</strong> WebAssembly(WASM)를 통해 브라우저에서 직접 Whisper 모델을 실행할 수 있게 해주는 핵심 프레임워크입니다. VORA의 서버리스 모드의 근간이 됩니다.</li>
                            <li><strong>Moonshine:</strong> 에지 디바이스와 모바일 환경에 최적화된 초경량 모델로, 밀리초 단위의 지연 시간을 보장합니다.</li>
                        </ul>

                        <h3>기술적 전망</h3>
                        <p>앞으로의 STT는 단순한 텍스트 변환을 넘어, <strong>'Context-Aware ASR'</strong>로 진화할 것입니다. 대화의 주제를 AI가 미리 파악하고, 그 주제에 맞는 전문 용어 사전을 동적으로 로드하여 인식률을 높이는 방식이 주류가 될 것으로 보입니다.</p>
                    </div>
                `
            }
        };

        function openPost(id) {
            const post = posts[id];
            if (post) {
                document.getElementById('modalBody').innerHTML = post.content;
                document.getElementById('postModal').classList.add('active');
                document.body.style.overflow = 'hidden'; // Scroll lock
            }
        }

        function closePost() {
            document.getElementById('postModal').classList.remove('active');
            document.body.style.overflow = 'auto';
        }

        window.onclick = function(event) {
            const modal = document.getElementById('postModal');
            if (event.target == modal) {
                closePost();
            }
        }
    </script>
</body>
</html>